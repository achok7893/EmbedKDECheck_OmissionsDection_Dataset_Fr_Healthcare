# -*- coding: utf-8 -*-

import pickle
import pandas as pd


def get_summaries_from_llm_output(x: str):
    """
    Extract summaries from the output string generated by an LLM (Large Language Model).

    The function attempts to evaluate the input string `x` as a dictionary and retrieve specific summaries:
    - "Résumé complet" (complete summary)
    - "Résumé complet mais avec des hallucinations" (summary with hallucinations)
    - "Résumé avec des omissions importantes" (summary with important omissions)

    Args:
        x (str): A string representation of a dictionary containing LLM outputs.

    Returns:
        dict or None: A dictionary with the extracted summaries if successful, or `None` if an error occurs.
    """
    try:
        dc_res = eval(x)  # Convert the string to a dictionary
        sc = dc_res["Résumé complet"]
        sh = dc_res["Résumé complet mais avec des hallucinations"]
        so = dc_res["Résumé avec des omissions importantes"]
        return {
            "Summaries complete": sc,
            "Summaries with hallucinations": sh,
            "Summaries uncomplete": so
        }
    except:
        return None


def get_fictive_hepathic_surgery_from_structured_excel():
    ds_path = "./data/synthetic_data.xlsx"
    df = pd.read_excel(ds_path)
    cols_to_select = ["CR Fictif", "Résumé complet", "Résumé avec des omissions importantes", "Résumé complet mais avec des hallucinations"]
    df = df.loc[:,cols_to_select].dropna().iloc[1:,:]
    df = df.dropna().reset_index().rename(columns={'index': 'doc_id'})


    # Create subsets for each summary type
    df_cs = df.loc[:, ["doc_id", "CR Fictif", "Résumé complet"]].rename(columns={"Résumé complet": "summary",
                                                                                            "CR Fictif" : "fictive_cr"})
    df_cs["hallucinations or omissions"] = 0
    df_cs["hallucinations"] = 0
    df_cs["omissions"] = 0
    
    df_os = df.loc[:, ["doc_id", "CR Fictif", "Résumé avec des omissions importantes"]].rename(columns={"Résumé avec des omissions importantes": "summary",
                                                                                                              "CR Fictif" : "fictive_cr"})
    df_os["hallucinations or omissions"] = 1
    df_os["hallucinations"] = 0
    df_os["omissions"] = 1
    
    df_hs = df.loc[:, ["doc_id", "CR Fictif", "Résumé complet mais avec des hallucinations"]].rename(columns={"Résumé complet mais avec des hallucinations": "summary",
                                                                                                      "CR Fictif" : "fictive_cr"})
    df_hs["hallucinations or omissions"] = 1
    df_hs["hallucinations"] = 1
    df_hs["omissions"] = 0

 # Concatenate all subsets into a single annotated DataFrame
    result_df = pd.concat([df_cs, df_os, df_hs], axis=0)
    
    return result_df
    

def get_fictive_hepathic_surgery_annotated_dataset():
    """
    Load, process, and annotate a dataset of fictive hepatic surgery reports.

    This function performs the following steps:
    1. Loads a pickled dataset containing fictive clinical reports.
    2. Extracts summaries from LLM outputs using `get_summaries_from_llm_output`.
    3. Filters rows with valid summaries and normalizes them into a structured format.
    4. Splits the dataset into subsets based on the type of summary:
       - Complete summaries
       - Summaries with hallucinations
       - Summaries with omissions
    5. Adds additional columns for annotation regarding hallucinations and omissions.

    Returns:
        pd.DataFrame: A concatenated DataFrame containing annotated data, with the following columns:
        - doc_id: Document identifier
        - fictive_cr: The fictive clinical report
        - hallucinations or omissions: Binary indicator (1 if hallucinations or omissions are present, 0 otherwise)
        - hallucinations: Binary indicator for hallucinations (1 if present, 0 otherwise)
        - omissions: Binary indicator for omissions (1 if present, 0 otherwise)
    """
    # Path to the dataset
    ds_path = "./data/fictifs_cr.pickle"
    # Load the dataset
    df = pickle.load(open(ds_path, "rb"))
    
    # Apply the function to extract summaries
    df.loc[:, "summaries"] = df.summaries.apply(get_summaries_from_llm_output)
    
    # Filter rows with valid summaries and clinical reports
    df = df.loc[pd.isnull(df.summaries) == False, ["fictive_cr", "summaries"]]
    df = df.loc[pd.isnull(df.fictive_cr) == False, ["fictive_cr", "summaries"]]
    
    # Normalize the summaries into a structured format
    dictionary_df = pd.json_normalize(df['summaries'])
    result_df = pd.concat([df.drop(columns=["summaries"]), dictionary_df], axis=1)
    result_df = result_df.dropna().reset_index().rename(columns={'index': 'doc_id'})
    
    # Create subsets for each summary type
    df_cs = result_df.loc[:, ["doc_id", "fictive_cr", "Summaries complete"]].rename(columns={"Summaries complete": "summary"})
    df_cs["hallucinations or omissions"] = 0
    df_cs["hallucinations"] = 0
    df_cs["omissions"] = 0
    
    df_os = result_df.loc[:, ["doc_id", "fictive_cr", "Summaries uncomplete"]].rename(columns={"Summaries uncomplete": "summary"})
    df_os["hallucinations or omissions"] = 1
    df_os["hallucinations"] = 0
    df_os["omissions"] = 1
    
    df_hs = result_df.loc[:, ["doc_id", "fictive_cr", "Summaries with hallucinations"]].rename(columns={"Summaries with hallucinations": "summary"})
    df_hs["hallucinations or omissions"] = 1
    df_hs["hallucinations"] = 1
    df_hs["omissions"] = 0
    
    # Concatenate all subsets into a single annotated DataFrame
    result_df = pd.concat([df_cs, df_os, df_hs], axis=0)
    
    return result_df
